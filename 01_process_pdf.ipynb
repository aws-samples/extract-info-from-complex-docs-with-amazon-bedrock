{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97ac53e7",
   "metadata": {},
   "source": [
    "# Process PDF files with Amazon Textract or Amazon Bedrock\n",
    "\n",
    "> This notebook should work well with the **`conda_python3`** kernel in SageMaker Notebook instances.\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, we demonstrate two approaches to process PDF documents:\n",
    "\n",
    "\n",
    "1. Use [Amazon Textract](https://aws.amazon.com/textract/) through the [Textractor](https://aws-samples.github.io/amazon-textract-textractor/index.html) library. Textract performs OCR to detect text from in documents, which can be in different formats such as PDF and images.\n",
    "\n",
    "2. Use [Amazon Bedrock](https://aws.amazon.com/bedrock/) by doing a `boto3` call to invoke a multi-modal Foundation Model to perform OCR. For this, we will need to convert the document into a set of images.\n",
    "\n",
    "We will showcase the functionality in this notebook on multiple files, which can be found in [demo-files](demo-files/) directory. Afterwards, all extracted texts will be stored in [processed-files](processed-files/) directory. The extracted texts are required for subsequent generative AI tasks we will perform in the [02_extract_attributes.ipynb](02_extract_attributes.ipynb). \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9174c4-326a-463e-92e1-8c7e47111269",
   "metadata": {},
   "source": [
    "# 1. PREPARATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ddc597b-1ad0-45d4-9705-76061fe9e6b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0248b605-7284-4240-a8ae-b29097cca9a8",
   "metadata": {},
   "source": [
    "## Create folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53c5ca3-93ea-4702-8b9e-0998c9bdf683",
   "metadata": {},
   "source": [
    "Define input and output paths as constants. \n",
    "\n",
    "Since Amazon Textract expects input files to be uploaded to S3, we will read them from a prepopulated S3 bucket `s3://information-extraction-workshop`. You can check copies of the input files in `demo-files` folder for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4312ff23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_path = \"demo-files\"\n",
    "output_path = \"processed-files\"\n",
    "s3_bucket = \"information-extraction-workshop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "586bdd95-063c-4544-8cac-87514741e98f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef19d31-28da-4407-8fc5-18d077e99139",
   "metadata": {},
   "source": [
    "## List input documents\n",
    "\n",
    "List objects on the S3 bucket, iterate over the objects and print their keys (file names)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7685c930-b4ff-4f06-b563-81d6fb71d612",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\"s3\")\n",
    "response = s3_client.list_objects_v2(Bucket=s3_bucket)\n",
    "file_objects = response[\"Contents\"]\n",
    "\n",
    "for obj in file_objects:\n",
    "    print(obj[\"Key\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a00c14-cfde-4a6f-b4a1-15faff9f5be2",
   "metadata": {
    "tags": []
   },
   "source": [
    "During the workshop, we will use 2 documents with snippets from scientific papers. We select scientific papers as they have complex layout, including figures, tables, and complex terminology.\n",
    "\n",
    "This is how the first page of one of the docs looks like:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d64109",
   "metadata": {},
   "source": [
    "![screenshots/2302.13971v1.png](screenshots/2302.13971v1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36d51ea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Feel free to extend the list of documents afterwards! Now we are all set and can proceed to the OCR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61435346-9a78-4eda-9262-27a2bc87ac7e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. PROCESSING\n",
    "\n",
    "We will start by doing OCR with Amazon Textract, and then do OCR with Amazon Bedrock to compare results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8a2d98",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Option 1: Run Textractor on demo files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7097c61a-b098-4960-b476-a7bd5fdf45bb",
   "metadata": {},
   "source": [
    "If you use the Amazon Textract OCR engine, you can choose between the synchronous `DetectDocumentText` API (this is called `detect_document_text` in the *Textractor* library) and the asynchronous `StartDocumentTextDetection` API (this is called `start_document_analysis` in the *Textractor* library). \n",
    "\n",
    "The former will block code execution until the OCR inference completes, while the latter will return a job_id that you can use to get the results later. In this notebook, we will use the `start_document_analysis` API. \n",
    "\n",
    "First step, we will create the Textractor boto3 client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae2b2a05-78a9-40ca-9b5e-121030f9ede1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from textractor import Textractor\n",
    "from textractor.data.constants import TextractFeatures\n",
    "from textractor.data.markdown_linearization_config import MarkdownLinearizationConfig\n",
    "\n",
    "extractor = Textractor(region_name=\"us-west-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9e0c66-17c8-4b25-90f9-815fa27d6855",
   "metadata": {},
   "source": [
    "Next, we run the Textractor library on all `demo-files`, one by one. The extracted text outputs will be stored in the `processed-files` directory. \n",
    "\n",
    "This cell contains your first task! Check out [Textractor documentation](https://github.com/aws-samples/amazon-textract-textractor) in their README. Find what would be the right command to execute to get the document object. Keep an eye on what features you enable as arguments to get the most content out of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8811c2-46e5-48c0-a99d-06544096129c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for obj in file_objects:\n",
    "    print(f\"Processing {obj['Key']}\")\n",
    "    base_filename = obj['Key']\n",
    "    s3_filename = f\"s3://{s3_bucket}/{base_filename}\"\n",
    "    output_filename = base_filename.removesuffix(\".pdf\") + \"_textract.txt\"\n",
    "    \n",
    "    #########################################\n",
    "    #    TASK 1: Add Textractor call here\n",
    "    #########################################\n",
    "    \n",
    "    document = None\n",
    "    \n",
    "    #########################################\n",
    "    #    TASK 1: Add Textractor call here\n",
    "    #########################################\n",
    "    \n",
    "    document_text = document.get_text(config = MarkdownLinearizationConfig)\n",
    "    \n",
    "    with open(os.path.join(output_path, output_filename), \"w\") as text_file:\n",
    "        text_file.write(document_text)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290f9b8b",
   "metadata": {},
   "source": [
    "* If you have trouble after a few minutes, check out `answers/answers.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1f9206",
   "metadata": {},
   "source": [
    "Note: if the Textractor call fails due to this error:\n",
    "> PDFInfoNotInstalledError: Unable to get page count. Is poppler installed and in PATH?\n",
    "\n",
    "This means you need to install [poppler](https://poppler.freedesktop.org/) by running something the following command in the terminal:\n",
    "```bash\n",
    "sudo yum install --y poppler-utils\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f383701-6238-410d-9ccb-fc502771fd1f",
   "metadata": {},
   "source": [
    "Check out the output folder and open one of the two `.txt` files! Write some code for opening the saved `.txt` file from the folder you created.\n",
    "\n",
    "P.S. We recommend opening the PDF and the text file side by side to see the text extraciton quality. How does Amazon Textract handle text in two columns? What about tables and images? Do you see any quality issues?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cfffec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "#    TASK 2: Open and print the output text file\n",
    "##################################################\n",
    "\n",
    "parsed_text = None\n",
    "\n",
    "print(parsed_text)\n",
    "\n",
    "#################################################\n",
    "#    TASK 2: Open and print the output text file\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ba0544",
   "metadata": {},
   "source": [
    "* If you have trouble after a few minutes, check out `answers/answers.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0923f3-26cf-42cf-8f7a-59c24c391a3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Option 2: Run Amazon Bedrock on demo files\n",
    "\n",
    "To improve the parsing quality for complex content like tables and images, we can leverage multi-modal foundation models from Amazon Bedrock. First, we will have to convert the PDF into a set of images to be able to send it to models in Amazon Bedrock. Second, we will send a set of images to the LLM to parse them.\n",
    "\n",
    "Let's start with the conversion. We don't need to save the images - rather, we will store a list of `base64` strings in memory representing each PDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d5d25422-6f36-40ef-b208-18b06be08dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import botocore\n",
    "from io import BytesIO\n",
    "\n",
    "from pdf2image import convert_from_path\n",
    "import json\n",
    "\n",
    "\n",
    "def get_base64_encoded_images_from_pdf(pdf_file_path):\n",
    "    images = convert_from_path(pdf_file_path)\n",
    "    base64_img_strs = []\n",
    "    for image in images:\n",
    "        buffered = BytesIO()\n",
    "        image.save(buffered, format=\"JPEG\")\n",
    "        img_str = base64.b64encode(buffered.getvalue())\n",
    "        base64_string = img_str.decode(\"utf-8\")\n",
    "        base64_img_strs.append(base64_string)\n",
    "    return base64_img_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3e4a9f-1d99-466a-9423-b3991c551c60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = get_base64_encoded_images_from_pdf(f\"{input_path}/{base_filename}\")\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a4641b-2122-4e20-82ce-97df4b348d6f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "The list of images contains the decoded byte strings for each of the pages of the PDF file.\n",
    "\n",
    "Now, let's instantiate Bedrock client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "38eb14af-4243-4ef6-ab9c-fab02a204d57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock_runtime = boto3.client(\"bedrock-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99936c05-a971-45f8-a9f2-2abc48cf4ab6",
   "metadata": {
    "tags": []
   },
   "source": [
    "We will need to put together a prompt that instructs the model to perform OCR. This will be your final task for this notbeook!\n",
    "\n",
    "Think about how to structure the prompt. You want to ask the LLM to convert the image document to a text content. What things should it keep in mind? How to format the output? \n",
    "\n",
    "Hint: think about instructions for dealing with figures and tables. How would you like the LLM to represent them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb0d4662-f856-43cb-98e0-aacd4def4bb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "#    TASK 3: Formulate the system prompt\n",
    "##################################################\n",
    "\n",
    "system_prompt = \"\"\"Always reply 'Amazon Web Services'.\"\"\"\n",
    "\n",
    "##################################################\n",
    "#    TASK 3: Formulate the system prompt\n",
    "##################################################\n",
    "\n",
    "prompt = \"\"\"Here is the document.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2b1d90",
   "metadata": {},
   "source": [
    "* If you have trouble after a few minutes, check out `answers/answers.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a09212-5978-4eb5-94d4-d7ef38b57efa",
   "metadata": {
    "tags": []
   },
   "source": [
    "Next, we combine the text prompt and the images into the list of messages to be sent to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "868c92e0-7f3e-47b3-ad3c-46653dfad019",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages_content = [\n",
    "    {\n",
    "        \"type\": \"image\",\n",
    "        \"source\": {\n",
    "            \"type\": \"base64\",\n",
    "            \"media_type\": \"image/jpeg\",\n",
    "            \"data\": image_str,\n",
    "        },\n",
    "    }\n",
    "    for image_str in images\n",
    "]\n",
    "\n",
    "messages_content.append({\"type\": \"text\", \"text\": prompt})\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": messages_content,\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df318f67-597e-457f-bcff-ce6371252818",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now, we can finally send our document to Amazon Bedrock!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b314bd4f-d0b1-4aaa-a21b-afbe38c2bb40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "modelId = \"anthropic.claude-3-haiku-20240307-v1:0\"  # (change this to try different model versions)\n",
    "\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"max_tokens\": 4_096,\n",
    "        \"system\": system_prompt,\n",
    "        \"temperature\": 0.0,\n",
    "        \"messages\": messages,\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "try:\n",
    "    response = bedrock_runtime.invoke_model_with_response_stream(\n",
    "        body=body,\n",
    "        modelId=modelId,\n",
    "        accept=\"application/json\",\n",
    "        contentType=\"application/json\",\n",
    "    )\n",
    "\n",
    "    output = \"\"\n",
    "\n",
    "    stream = response.get(\"body\")\n",
    "\n",
    "    if stream:\n",
    "        for event in stream:\n",
    "            chunk = event.get(\"chunk\")\n",
    "            if chunk:\n",
    "                chunk_obj = json.loads(chunk.get(\"bytes\").decode())\n",
    "                if \"delta\" in chunk_obj:\n",
    "                    delta_obj = chunk_obj.get(\"delta\", None)\n",
    "                    if delta_obj:\n",
    "                        text = delta_obj.get(\"text\", None)\n",
    "                        if text is not None:\n",
    "                            output += text\n",
    "                            print(text, end=\"\")\n",
    "                        if not text:\n",
    "                            break\n",
    "    print(\"\")\n",
    "\n",
    "except botocore.exceptions.ClientError as error:\n",
    "    if error.response[\"Error\"][\"Code\"] == \"AccessDeniedException\":\n",
    "        print(\n",
    "            f\"\\x1b[41m{error.response['Error']['Message']}\\\n",
    "                \\nTo troubleshoot this issue please refer to the following resources.\\\n",
    "                \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "                \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\"\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d657421",
   "metadata": {},
   "source": [
    "Check out the output text! We recommend opening the PDF, previous `.txt` and the new text file side by side to see the text extraciton quality. How does parsing quality change when using Amazon Bedrock? Is it better or worse than Amazon Textract?\n",
    "\n",
    "Don't forget to export the result as `.txt` file below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad4d24d0-c3f5-4285-b041-6808bd368f39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_filename = obj[\"Key\"]\n",
    "s3_filename = f\"s3://{s3_bucket}/{base_filename}\"\n",
    "output_filename = base_filename.removesuffix(\".pdf\") + \"_bedrock.txt\"\n",
    "\n",
    "with open(os.path.join(output_path, output_filename), \"w\") as text_file:\n",
    "    text_file.write(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410b6fe0-d0d1-4a14-8ad7-16f55fdc51b5",
   "metadata": {},
   "source": [
    "## Optional tasks\n",
    "\n",
    "Once you are done, consider experimenting with one of the tasks below:\n",
    "\n",
    "Amazon Textract:\n",
    "- Check configuration arguments for `MarkdownLinearizationConfig` to see if you can tweak Textractor parameters to improve OCR quality.\n",
    "\n",
    "Amazon Bedrock:\n",
    "- Experiment with the LLM prompt to see if you can further improve the OCR quality/formatting when using Amazon Bedrock.\n",
    "- Switch to a different multi-modal LLM and compare the OCR quality. Which model is doing best?\n",
    "- Run LLM-based OCR for the second document in the demo folder. How does the performance compare?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6f761b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
